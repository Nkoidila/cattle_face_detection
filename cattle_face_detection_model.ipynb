{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LwYlxua4rdKq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HJNptnGEphkP"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset\n",
        "data_path = r'C:\\Users\\kores\\OneDrive\\Desktop\\Ngishu\\cattle_face_images_dataset'\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 128, 128\n",
        "batch_size = 20\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_data(data_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {}\n",
        "    current_label = 0\n",
        "\n",
        "    for label_folder in os.listdir(data_path):\n",
        "        label_folder_path = os.path.join(data_path, label_folder)\n",
        "        if os.path.isdir(label_folder_path):\n",
        "            label_map[current_label] = label_folder\n",
        "            for img_file in os.listdir(label_folder_path):\n",
        "                img_path = os.path.join(label_folder_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (img_height, img_width))\n",
        "                    images.append(img)\n",
        "                    labels.append(current_label)\n",
        "            current_label += 1\n",
        "\n",
        "    return np.array(images), np.array(labels), label_map\n",
        "\n",
        "# Load data\n",
        "images, labels, label_map = load_data(data_path)\n",
        "\n",
        "# Normalize the images\n",
        "images = images / 255.0\n",
        "\n",
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=52)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "JmrXnY8Kqh0N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the ResNet50 model, excluding the top layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Add custom top layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(len(label_map), activation='softmax')(x)\n",
        "\n",
        "# Combine the base model with the custom top layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dOf4zVEl4YIx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.0318 - loss: 4.0096 - val_accuracy: 0.0677 - val_loss: 3.8298\n",
            "Epoch 2/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.0870 - loss: 3.7275 - val_accuracy: 0.1474 - val_loss: 3.6201\n",
            "Epoch 3/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.1508 - loss: 3.5111 - val_accuracy: 0.1594 - val_loss: 3.4051\n",
            "Epoch 4/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.1995 - loss: 3.3434 - val_accuracy: 0.2271 - val_loss: 3.2017\n",
            "Epoch 5/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.2699 - loss: 3.0830 - val_accuracy: 0.3466 - val_loss: 2.9774\n",
            "Epoch 6/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.2854 - loss: 2.9309 - val_accuracy: 0.3068 - val_loss: 2.8070\n",
            "Epoch 7/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.3747 - loss: 2.7311 - val_accuracy: 0.3506 - val_loss: 2.6191\n",
            "Epoch 8/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.4123 - loss: 2.4912 - val_accuracy: 0.3865 - val_loss: 2.4594\n",
            "Epoch 9/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.4067 - loss: 2.3750 - val_accuracy: 0.4502 - val_loss: 2.3068\n",
            "Epoch 10/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.5371 - loss: 2.1499 - val_accuracy: 0.4502 - val_loss: 2.1935\n",
            "Epoch 11/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.5764 - loss: 1.9985 - val_accuracy: 0.5299 - val_loss: 2.0242\n",
            "Epoch 12/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.5839 - loss: 1.8775 - val_accuracy: 0.4980 - val_loss: 1.9290\n",
            "Epoch 13/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6416 - loss: 1.7250 - val_accuracy: 0.5299 - val_loss: 1.8445\n",
            "Epoch 14/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.6267 - loss: 1.6423 - val_accuracy: 0.6096 - val_loss: 1.6818\n",
            "Epoch 15/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.6972 - loss: 1.4783 - val_accuracy: 0.5817 - val_loss: 1.6011\n",
            "Epoch 16/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.7199 - loss: 1.3789 - val_accuracy: 0.6414 - val_loss: 1.4778\n",
            "Epoch 17/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.7430 - loss: 1.2511 - val_accuracy: 0.5976 - val_loss: 1.4568\n",
            "Epoch 18/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.7153 - loss: 1.2399 - val_accuracy: 0.6733 - val_loss: 1.3278\n",
            "Epoch 19/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.7593 - loss: 1.1103 - val_accuracy: 0.6972 - val_loss: 1.2415\n",
            "Epoch 20/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.7916 - loss: 1.0135 - val_accuracy: 0.7371 - val_loss: 1.1897\n",
            "Epoch 21/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8178 - loss: 1.0031 - val_accuracy: 0.7530 - val_loss: 1.1245\n",
            "Epoch 22/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8310 - loss: 0.8954 - val_accuracy: 0.7131 - val_loss: 1.0991\n",
            "Epoch 23/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8295 - loss: 0.8002 - val_accuracy: 0.7809 - val_loss: 1.0297\n",
            "Epoch 24/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8131 - loss: 0.8531 - val_accuracy: 0.7849 - val_loss: 0.9499\n",
            "Epoch 25/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8195 - loss: 0.7992 - val_accuracy: 0.7689 - val_loss: 0.9602\n",
            "Epoch 26/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.8324 - loss: 0.7944 - val_accuracy: 0.7530 - val_loss: 0.9635\n",
            "Epoch 27/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8721 - loss: 0.7221 - val_accuracy: 0.7490 - val_loss: 0.9364\n",
            "Epoch 28/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.8595 - loss: 0.6721 - val_accuracy: 0.7928 - val_loss: 0.8510\n",
            "Epoch 29/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8675 - loss: 0.6231 - val_accuracy: 0.8008 - val_loss: 0.8019\n",
            "Epoch 30/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8945 - loss: 0.5890 - val_accuracy: 0.7968 - val_loss: 0.8007\n",
            "Epoch 31/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.5855 - val_accuracy: 0.7968 - val_loss: 0.7557\n",
            "Epoch 32/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8718 - loss: 0.5687 - val_accuracy: 0.7968 - val_loss: 0.7493\n",
            "Epoch 33/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8838 - loss: 0.5351 - val_accuracy: 0.8008 - val_loss: 0.7318\n",
            "Epoch 34/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.8990 - loss: 0.5017 - val_accuracy: 0.7888 - val_loss: 0.7448\n",
            "Epoch 35/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8872 - loss: 0.5151 - val_accuracy: 0.8167 - val_loss: 0.6736\n",
            "Epoch 36/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8960 - loss: 0.4905 - val_accuracy: 0.7928 - val_loss: 0.6949\n",
            "Epoch 37/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9068 - loss: 0.4552 - val_accuracy: 0.8127 - val_loss: 0.6515\n",
            "Epoch 38/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.8969 - loss: 0.4488 - val_accuracy: 0.8127 - val_loss: 0.6702\n",
            "Epoch 39/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9041 - loss: 0.4357 - val_accuracy: 0.8207 - val_loss: 0.6004\n",
            "Epoch 40/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.8933 - loss: 0.4644 - val_accuracy: 0.8088 - val_loss: 0.6302\n",
            "Epoch 41/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9056 - loss: 0.3790 - val_accuracy: 0.8287 - val_loss: 0.5795\n",
            "Epoch 42/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9140 - loss: 0.3759 - val_accuracy: 0.8446 - val_loss: 0.5925\n",
            "Epoch 43/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9176 - loss: 0.3724 - val_accuracy: 0.8247 - val_loss: 0.5717\n",
            "Epoch 44/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9037 - loss: 0.3806 - val_accuracy: 0.8088 - val_loss: 0.5976\n",
            "Epoch 45/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.9239 - loss: 0.3398 - val_accuracy: 0.8446 - val_loss: 0.5496\n",
            "Epoch 46/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.9055 - loss: 0.3877 - val_accuracy: 0.8247 - val_loss: 0.5655\n",
            "Epoch 47/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 0.3511 - val_accuracy: 0.8367 - val_loss: 0.5447\n",
            "Epoch 48/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9198 - loss: 0.3392 - val_accuracy: 0.8167 - val_loss: 0.5449\n",
            "Epoch 49/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9434 - loss: 0.2885 - val_accuracy: 0.8446 - val_loss: 0.5249\n",
            "Epoch 50/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9377 - loss: 0.2981 - val_accuracy: 0.8446 - val_loss: 0.4978\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=50,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RlxwkJO8pBuO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9180 - loss: 0.3305\n",
            "Test accuracy: 0.90\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('cattle_model5.keras')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
